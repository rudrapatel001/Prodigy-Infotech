{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prodigy Infotech\n",
    "\n",
    "### Author : Rudra Patel\n",
    "\n",
    "\n",
    "### Data Science\n",
    "### Task-03\n",
    "\n",
    "#### Task: Build a decision tree classifier to predict whether a customer will purchase a product or service based on their demographic and behavioral data. Use a dataset such as the Bank Marketing dataset from the UCI Machine Learning Repository.\n",
    "\n",
    "### DataSet Link : https://archive.ics.uci.edu/dataset/222/bank+marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the train data and viewing first few rows\n",
    "train = pd.read_csv(\"bank_data/test.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the test data and viewing first few rows\n",
    "test = pd.read_csv(\"bank_data/test.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the dimension of the training dataset:\n",
    "print(\"The total rows in the training dataset is:\" ,train.shape[0] ,\"\\nThe total columns in the training dataset is:\" ,train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the dimension of the testing dataset:\n",
    "print(\"The total rows in the test dataset is:\" ,test.shape[0] ,\"\\nThe total columns in the test dataset is:\" ,test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the missing column in the test dataset.\n",
    "def check_column_similarity(data1, data2):\n",
    "    if len(data1.columns)==len(data2.columns):\n",
    "        print('Both train and test has same columns')\n",
    "    else:\n",
    "        print(\"Column length is different.\")\n",
    "        if len(data1.columns) > len(data2.columns):\n",
    "            print(set(data1.columns)-set(data2.columns))\n",
    "        else:\n",
    "            print(set(data2.columns)-set(data1.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_column_similarity(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the type of data and the missing value\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for missing values\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistical Analysis:\n",
    "train.describe( include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the 'subscribed' frequency\n",
    "sns.countplot(data=train, x='subscribed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the frequency table of 'Subscribed' variable\n",
    "train['subscribed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the non-numerical columns:\n",
    "print(\"The non-numerical columns are: \")\n",
    "data_non_numerical=train.select_dtypes(object)\n",
    "data_non_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate Cramer's V statistic\n",
    "def cramers_v(x, y):\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2, _, _, _ = chi2_contingency(confusion_matrix)\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "\n",
    "# Create a matrix of Cramer's V values between variables\n",
    "columns = data_non_numerical.columns\n",
    "cramer_matrix = pd.DataFrame(index=columns, columns=columns)\n",
    "for col1 in columns:\n",
    "    for col2 in columns:\n",
    "        cramer_matrix.loc[col1, col2] = cramers_v(data_non_numerical[col1], data_non_numerical[col2])\n",
    "\n",
    "# Create a heatmap from the Cramer's V matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cramer_matrix.astype(float), annot=True, cmap=\"PiYG\" ,linewidth=.5)\n",
    "\n",
    "plt.title(\"Cramer's V Heatmap for Non-Numeric Variables\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using barplot\n",
    "for feature in data_non_numerical:\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.countplot(x=feature, data=data_non_numerical, palette='pink', hue=\"subscribed\", edgecolor = \"black\")\n",
    "    plt.title(f'Bar Plot of {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the target variables into 0s and 1s\n",
    "train['subscribed'].replace('no', 0,inplace=True)\n",
    "train['subscribed'].replace('yes', 1,inplace=True)\n",
    "train['subscribed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the numerical columns:\n",
    "print(\"The Numerical columns are: \")\n",
    "data_numerical=train.select_dtypes(np.number)\n",
    "data_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Correlation matrix (for continuous variables)\n",
    "correlation_matrix = data_numerical.corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=sns.cubehelix_palette(as_cmap=True), fmt=\".2f\",linewidth=.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot (for continuous variables)\n",
    "sns.pairplot(data_numerical, hue=\"subscribed\", diag_kind=\"hist\", corner=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix.hist(figsize=(10, 10), color='blue', grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['subscribed']\n",
    "train = train.drop(['subscribed', \"ID\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for categorical features\n",
    "for column in train.select_dtypes(include='object'):\n",
    "    train = pd.get_dummies(train, columns=[column], dtype='int')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an object of logistic regression model\n",
    "lreg = LogisticRegression()\n",
    "#fitting the data into the model\n",
    "lreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions on the validation set\n",
    "pred = lreg.predict(X_val)\n",
    "#Calculating the accuracy score\n",
    "accuracy_score(y_val,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an object of Decision tree\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "#fitting the model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making predictions on the validation set\n",
    "predict = clf.predict(X_val)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the accuracy\n",
    "accuracy_score(y_val,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "y_predict = clf.fit(X_train, y_train).predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_val, y_predict, labels=clf.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_val, y_predict, labels=clf.classes_)\n",
    "ConfusionMatrixDisplay(cm, display_labels=clf.classes_).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame({\"feature\":X_train.columns.to_list(), \"importance\": clf.feature_importances_}).sort_values(by=\"importance\", ascending=False)\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=fi.head(20))\n",
    "plt.title(\"Top 20 Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
